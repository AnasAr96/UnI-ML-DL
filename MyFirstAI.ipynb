{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lachen: 0 Images\n",
      "neutral: 0 Images\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/Users/anasarodake/anas_fotos'\n",
    "classes = ['lachen' , 'neutral']\n",
    "\n",
    "\n",
    "for cl in classes:\n",
    "    img_path = os.path.join(base_dir, cl)\n",
    "    images = glob.glob(img_path + '/*.jpeg')\n",
    "    print(\"{}: {} Images\".format(cl, len(images)))\n",
    "    train, val = images[:round(len(images)*0.7)], images[round(len(images)*0.7):]\n",
    "\n",
    "    for t in train:\n",
    "      if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
    "        os.makedirs(os.path.join(base_dir, 'train', cl))\n",
    "      shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
    "\n",
    "    for v in val:\n",
    "      if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
    "        os.makedirs(os.path.join(base_dir, 'val', cl))\n",
    "      shutil.move(v, os.path.join(base_dir, 'val', cl))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 550 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = 250\n",
    "\n",
    "batch_size =10\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.5,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15\n",
    ")\n",
    "\n",
    "train_data_gen = image_gen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    shuffle=True,\n",
    "    target_size = (IMG_SHAPE, IMG_SHAPE),\n",
    "    batch_size= batch_size,\n",
    "    class_mode='sparse',\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#dieser ablock sucht nach Bildern, die evtl. einen Fehler bei ber Implimentierung verursachen und zeigt sie auf\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "path = Path(train_dir).rglob(\"*.jpeg\")\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = PIL.Image.open(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "        print(img_p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "#plotImages(augmented_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 191 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "\n",
    "val_data_gen =  image_gen.flow_from_directory(\n",
    "    directory=val_dir,\n",
    "    classes=classes,\n",
    "    target_size = (IMG_SHAPE, IMG_SHAPE),\n",
    "    batch_size= batch_size,\n",
    "    class_mode= 'sparse')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 23:09:43.433663: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-14 23:09:43.433984: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(4,3 , padding='same' , input_shape=(IMG_SHAPE, IMG_SHAPE, 3) , activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(16, 3 ,padding='same' , activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, 3 ,padding='same' , activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1024 ,  activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 23:09:44.233295: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "/Users/anasarodake/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2022-04-14 23:09:44.524767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.5491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 23:09:50.836883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 8s 110ms/step - loss: 0.7016 - accuracy: 0.5491 - val_loss: 0.6849 - val_accuracy: 0.5916\n",
      "Epoch 2/120\n",
      "55/55 [==============================] - 5s 97ms/step - loss: 0.6899 - accuracy: 0.5764 - val_loss: 0.6785 - val_accuracy: 0.5916\n",
      "Epoch 3/120\n",
      "55/55 [==============================] - 5s 96ms/step - loss: 0.6825 - accuracy: 0.5764 - val_loss: 0.6766 - val_accuracy: 0.5916\n",
      "Epoch 4/120\n",
      "55/55 [==============================] - 6s 101ms/step - loss: 0.6673 - accuracy: 0.5873 - val_loss: 0.6089 - val_accuracy: 0.6963\n",
      "Epoch 5/120\n",
      "55/55 [==============================] - 7s 122ms/step - loss: 0.6455 - accuracy: 0.5836 - val_loss: 0.4483 - val_accuracy: 0.8586\n",
      "Epoch 6/120\n",
      "55/55 [==============================] - 7s 130ms/step - loss: 0.6587 - accuracy: 0.5927 - val_loss: 0.4392 - val_accuracy: 0.8168\n",
      "Epoch 7/120\n",
      "55/55 [==============================] - 7s 121ms/step - loss: 0.5802 - accuracy: 0.6673 - val_loss: 0.3952 - val_accuracy: 0.8010\n",
      "Epoch 8/120\n",
      "55/55 [==============================] - 7s 129ms/step - loss: 0.5782 - accuracy: 0.6836 - val_loss: 0.3508 - val_accuracy: 0.9162\n",
      "Epoch 9/120\n",
      "55/55 [==============================] - 7s 128ms/step - loss: 0.5968 - accuracy: 0.6745 - val_loss: 0.3838 - val_accuracy: 0.9267\n",
      "Epoch 10/120\n",
      "55/55 [==============================] - 7s 130ms/step - loss: 0.5371 - accuracy: 0.7418 - val_loss: 0.2289 - val_accuracy: 0.9686\n",
      "Epoch 11/120\n",
      "55/55 [==============================] - 6s 107ms/step - loss: 0.5829 - accuracy: 0.6909 - val_loss: 0.3434 - val_accuracy: 0.9581\n",
      "Epoch 12/120\n",
      "55/55 [==============================] - 6s 107ms/step - loss: 0.5480 - accuracy: 0.7382 - val_loss: 0.2770 - val_accuracy: 0.9529\n",
      "Epoch 13/120\n",
      "55/55 [==============================] - 6s 106ms/step - loss: 0.5028 - accuracy: 0.7636 - val_loss: 0.2273 - val_accuracy: 0.9581\n",
      "Epoch 14/120\n",
      "55/55 [==============================] - 6s 103ms/step - loss: 0.5066 - accuracy: 0.7800 - val_loss: 0.2407 - val_accuracy: 0.9581\n",
      "Epoch 15/120\n",
      "55/55 [==============================] - 7s 124ms/step - loss: 0.4410 - accuracy: 0.8073 - val_loss: 0.2157 - val_accuracy: 0.9476\n",
      "Epoch 16/120\n",
      "55/55 [==============================] - 7s 117ms/step - loss: 0.4846 - accuracy: 0.7782 - val_loss: 0.1992 - val_accuracy: 0.9529\n",
      "Epoch 17/120\n",
      "55/55 [==============================] - 8s 143ms/step - loss: 0.4184 - accuracy: 0.8000 - val_loss: 0.1700 - val_accuracy: 0.9791\n",
      "Epoch 18/120\n",
      "55/55 [==============================] - 7s 123ms/step - loss: 0.4124 - accuracy: 0.8145 - val_loss: 0.2325 - val_accuracy: 0.9110\n",
      "Epoch 19/120\n",
      "55/55 [==============================] - 6s 110ms/step - loss: 0.4698 - accuracy: 0.8055 - val_loss: 0.2104 - val_accuracy: 0.9738\n",
      "Epoch 20/120\n",
      "55/55 [==============================] - 6s 101ms/step - loss: 0.4266 - accuracy: 0.8236 - val_loss: 0.1631 - val_accuracy: 0.9738\n",
      "Epoch 21/120\n",
      "55/55 [==============================] - 5s 97ms/step - loss: 0.4023 - accuracy: 0.8200 - val_loss: 0.1616 - val_accuracy: 0.9738\n",
      "Epoch 22/120\n",
      "55/55 [==============================] - 5s 96ms/step - loss: 0.3674 - accuracy: 0.8618 - val_loss: 0.1646 - val_accuracy: 0.9634\n",
      "Epoch 23/120\n",
      "55/55 [==============================] - 6s 113ms/step - loss: 0.3496 - accuracy: 0.8545 - val_loss: 0.1366 - val_accuracy: 0.9791\n",
      "Epoch 24/120\n",
      "55/55 [==============================] - 6s 100ms/step - loss: 0.2989 - accuracy: 0.8673 - val_loss: 0.1300 - val_accuracy: 0.9686\n",
      "Epoch 25/120\n",
      "55/55 [==============================] - 5s 96ms/step - loss: 0.3473 - accuracy: 0.8618 - val_loss: 0.1455 - val_accuracy: 0.9529\n",
      "Epoch 26/120\n",
      "55/55 [==============================] - 5s 97ms/step - loss: 0.2803 - accuracy: 0.8982 - val_loss: 0.0860 - val_accuracy: 0.9843\n",
      "Epoch 27/120\n",
      "55/55 [==============================] - 6s 109ms/step - loss: 0.2378 - accuracy: 0.8891 - val_loss: 0.1173 - val_accuracy: 0.9634\n",
      "Epoch 28/120\n",
      "55/55 [==============================] - 5s 93ms/step - loss: 0.2745 - accuracy: 0.8782 - val_loss: 0.1015 - val_accuracy: 0.9686\n",
      "Epoch 29/120\n",
      "55/55 [==============================] - 6s 106ms/step - loss: 0.2958 - accuracy: 0.8891 - val_loss: 0.0815 - val_accuracy: 0.9791\n",
      "Epoch 30/120\n",
      "55/55 [==============================] - 6s 100ms/step - loss: 0.2559 - accuracy: 0.9055 - val_loss: 0.1376 - val_accuracy: 0.9529\n",
      "Epoch 31/120\n",
      "55/55 [==============================] - 6s 113ms/step - loss: 0.2803 - accuracy: 0.8909 - val_loss: 0.1041 - val_accuracy: 0.9843\n",
      "Epoch 32/120\n",
      "55/55 [==============================] - 6s 106ms/step - loss: 0.2279 - accuracy: 0.9200 - val_loss: 0.0677 - val_accuracy: 0.9843\n",
      "Epoch 33/120\n",
      "55/55 [==============================] - 6s 111ms/step - loss: 0.2143 - accuracy: 0.9182 - val_loss: 0.0506 - val_accuracy: 0.9895\n",
      "Epoch 34/120\n",
      "55/55 [==============================] - 6s 108ms/step - loss: 0.2137 - accuracy: 0.9127 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 35/120\n",
      "55/55 [==============================] - 6s 112ms/step - loss: 0.2128 - accuracy: 0.9182 - val_loss: 0.0860 - val_accuracy: 0.9686\n",
      "Epoch 36/120\n",
      "55/55 [==============================] - 7s 135ms/step - loss: 0.1744 - accuracy: 0.9418 - val_loss: 0.0469 - val_accuracy: 0.9843\n",
      "Epoch 37/120\n",
      "55/55 [==============================] - 8s 138ms/step - loss: 0.1259 - accuracy: 0.9618 - val_loss: 0.2107 - val_accuracy: 0.9476\n",
      "Epoch 38/120\n",
      "55/55 [==============================] - 7s 119ms/step - loss: 0.1722 - accuracy: 0.9364 - val_loss: 0.0284 - val_accuracy: 0.9948\n",
      "Epoch 39/120\n",
      "55/55 [==============================] - 6s 117ms/step - loss: 0.1159 - accuracy: 0.9545 - val_loss: 0.0846 - val_accuracy: 0.9738\n",
      "Epoch 40/120\n",
      "45/55 [=======================>......] - ETA: 1s - loss: 0.1419 - accuracy: 0.9556"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss' , patience= 3 , verbose=1)\n",
    "\n",
    "epochs = 120\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(train_data_gen.n / float(batch_size))), #alle Bilder / 10\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(val_data_gen.n / float(batch_size))),\n",
    "    #callbacks=[callback]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#classes = ['lachen' , 'neutral']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "\n",
    "test_data_gen =  image_gen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    classes=classes,\n",
    "    target_size = (IMG_SHAPE, IMG_SHAPE),\n",
    "    batch_size= batch_size,\n",
    "    class_mode= 'sparse')\n",
    "\n",
    "\n",
    "\n",
    "evaluated = model.evaluate(\n",
    "    x = test_data_gen\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_dir_lach = os.path.join(base_dir, 'oli/lachen')\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "\n",
    "predict_lach_data_gen =  image_gen.flow_from_directory(\n",
    "    directory=predict_dir_lach,\n",
    "\n",
    "    target_size = (IMG_SHAPE, IMG_SHAPE),\n",
    "    batch_size= 86,\n",
    "    class_mode= 'sparse'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "predicted_lach = model.predict(x = predict_lach_data_gen)\n",
    "\n",
    "\n",
    "\n",
    "for value in predicted_lach:\n",
    "    print(\"\\nLächeln Bild, die KI Werte:    lachen:{}      Neutral:{}\".format( round(value[0] *100 , 2) ,round(value[1] *100) ) , \"   richtig geschätzt:  \" ,  (value[0] > value[1]) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = 0\n",
    "false_images = np.array([])\n",
    "for value in predicted_lach:\n",
    "    if value[0] < value[1]:\n",
    "        print(\"falsch geschätztes BILD:    lachen: {}      Neutral: {}        Bild_Index: {}\".format( round(value[0] *100 , 2) ,round(value[1] *100) , index ))\n",
    "        false_images = np.append(false_images , int(index))\n",
    "    index = index+1\n",
    "\n",
    "print(\"zahl der Falsch geschätzten Bilder: \" , len(false_images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pic in false_images:\n",
    "    augmented_images = [predict_lach_data_gen[0][0][int(pic)] for i in range(5)]\n",
    "    plotImages(augmented_images)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_dir = os.path.join(base_dir, 'oli/neutral')\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "\n",
    "predict_data_gen =  image_gen.flow_from_directory(\n",
    "    directory=predict_dir,\n",
    "    #classes=classes,\n",
    "    target_size = (IMG_SHAPE, IMG_SHAPE),\n",
    "    batch_size= 43,\n",
    "    class_mode= 'sparse')\n",
    "\n",
    "\n",
    "\n",
    "predicted = model.predict(x = predict_data_gen)\n",
    "for value in predicted:\n",
    "    print(\"Neutrales Bild, die KI Werte:   lachen:{}      Neutral:{}\".format( round(value[0] *100 , 2) ,round(value[1] *100) ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = 0\n",
    "false_images = np.array([])\n",
    "for value in predicted:\n",
    "    if value[0] > value[1]:\n",
    "        print(\"falsch geschätztes BILD:    lachen: {}      Neutral: {}        Bild_Index: {}\".format( round(value[0] *100 , 2) ,round(value[1] *100) , index ))\n",
    "        false_images = np.append(false_images , int(index))\n",
    "    index = index+1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pic in false_images:\n",
    "    augmented_images = [predict_data_gen[0][0][int(pic)] for i in range(5)]\n",
    "    plotImages(augmented_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"zahl der Falsch geschätzten Bilder: \" , len(false_images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}